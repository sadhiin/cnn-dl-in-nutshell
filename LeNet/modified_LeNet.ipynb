{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOukjHgDxf+0CerMFKoIJ6d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"b0mMLysekxcc","executionInfo":{"status":"ok","timestamp":1698843920969,"user_tz":-360,"elapsed":4,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Sequential"]},{"cell_type":"code","source":["# Loading the dataset and perform splitting\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","# Peforming reshaping operation\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","\n","# Normalization\n","x_train = x_train / 255\n","x_test = x_test / 255\n","\n","# One Hot Encoding\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"metadata":{"id":"O_K03LXLlexs","executionInfo":{"status":"ok","timestamp":1698843922034,"user_tz":-360,"elapsed":1069,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Base-LeNet"],"metadata":{"id":"ujftjHsKlh1K"}},{"cell_type":"code","source":["def build_lenet():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=6,\n","        kernel_size = (5,5),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (5,5),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=84, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(lr=0.1), metrics=['accuracy'])\n","    return model"],"metadata":{"id":"qDN6aWZMlg7O","executionInfo":{"status":"ok","timestamp":1698843922040,"user_tz":-360,"elapsed":57,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model_1 = build_lenet()\n","\n","model_1.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_1.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyfaxmYAlsYo","executionInfo":{"status":"ok","timestamp":1698843354145,"user_tz":-360,"elapsed":505994,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"1a6a4db4-73e7-4ede-bf69-18b5e714444a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 24, 24, 6)         156       \n","                                                                 \n"," average_pooling2d (Average  (None, 12, 12, 6)         0         \n"," Pooling2D)                                                      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 8, 8, 16)          2416      \n","                                                                 \n"," average_pooling2d_1 (Avera  (None, 4, 4, 16)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 128)               32896     \n","                                                                 \n"," dense_1 (Dense)             (None, 84)                10836     \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 47154 (184.20 KB)\n","Trainable params: 47154 (184.20 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 26s 53ms/step - loss: 1.2091 - accuracy: 0.6939 - val_loss: 0.5905 - val_accuracy: 0.8601\n","Epoch 2/20\n","469/469 [==============================] - 25s 54ms/step - loss: 0.4986 - accuracy: 0.8698 - val_loss: 0.4124 - val_accuracy: 0.8895\n","Epoch 3/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.3932 - accuracy: 0.8902 - val_loss: 0.3482 - val_accuracy: 0.9034\n","Epoch 4/20\n","469/469 [==============================] - 23s 49ms/step - loss: 0.3437 - accuracy: 0.9021 - val_loss: 0.3105 - val_accuracy: 0.9120\n","Epoch 5/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.3102 - accuracy: 0.9098 - val_loss: 0.2831 - val_accuracy: 0.9190\n","Epoch 6/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.2838 - accuracy: 0.9173 - val_loss: 0.2605 - val_accuracy: 0.9236\n","Epoch 7/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.2619 - accuracy: 0.9233 - val_loss: 0.2403 - val_accuracy: 0.9293\n","Epoch 8/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.2429 - accuracy: 0.9288 - val_loss: 0.2238 - val_accuracy: 0.9324\n","Epoch 9/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.2261 - accuracy: 0.9333 - val_loss: 0.2092 - val_accuracy: 0.9381\n","Epoch 10/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.2111 - accuracy: 0.9383 - val_loss: 0.1955 - val_accuracy: 0.9409\n","Epoch 11/20\n","469/469 [==============================] - 24s 51ms/step - loss: 0.1976 - accuracy: 0.9418 - val_loss: 0.1846 - val_accuracy: 0.9441\n","Epoch 12/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.1855 - accuracy: 0.9454 - val_loss: 0.1714 - val_accuracy: 0.9479\n","Epoch 13/20\n","469/469 [==============================] - 25s 52ms/step - loss: 0.1746 - accuracy: 0.9487 - val_loss: 0.1619 - val_accuracy: 0.9512\n","Epoch 14/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.1649 - accuracy: 0.9514 - val_loss: 0.1526 - val_accuracy: 0.9541\n","Epoch 15/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.1562 - accuracy: 0.9543 - val_loss: 0.1458 - val_accuracy: 0.9557\n","Epoch 16/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.1482 - accuracy: 0.9565 - val_loss: 0.1384 - val_accuracy: 0.9589\n","Epoch 17/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.1409 - accuracy: 0.9582 - val_loss: 0.1317 - val_accuracy: 0.9612\n","Epoch 18/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.1343 - accuracy: 0.9604 - val_loss: 0.1261 - val_accuracy: 0.9640\n","Epoch 19/20\n","469/469 [==============================] - 23s 49ms/step - loss: 0.1282 - accuracy: 0.9624 - val_loss: 0.1205 - val_accuracy: 0.9652\n","Epoch 20/20\n","469/469 [==============================] - 25s 54ms/step - loss: 0.1226 - accuracy: 0.9640 - val_loss: 0.1154 - val_accuracy: 0.9675\n","313/313 [==============================] - 3s 9ms/step - loss: 0.1154 - accuracy: 0.9675\n","Test Loss: 0.11541157215833664\n","Test accuracy: 0.9674999713897705\n"]}]},{"cell_type":"markdown","source":["# Modified LeNet"],"metadata":{"id":"NlprrU1klpE8"}},{"cell_type":"code","source":["def build_lenet_with_relu():\n","    # Building the Model Architecture\n","\n","    model = Sequential()\n","    # Select 6 feature convolution kernels with a size of 5 * 5 (without offset), and get 66 feature maps. The size of each feature map is 32−5 + 1 = 2832−5 + 1 = 28.\n","    # That is, the number of neurons has been reduced from 10241024 to 28 ∗ 28 = 784 28 ∗ 28 = 784.\n","    # Parameters between input layer and C1 layer: 6 ∗ (5 ∗ 5 + 1)\n","    model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n","    # The input of this layer is the output of the first layer, which is a 28 * 28 * 6 node matrix.\n","    # The size of the filter used in this layer is 2 * 2, and the step length and width are both 2, so the output matrix size of this layer is 14 * 14 * 6.\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    # The input matrix size of this layer is 14 * 14 * 6, the filter size used is 5 * 5, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n","    # The output matrix size of this layer is 10 * 10 * 16. This layer has 5 * 5 * 6 * 16 + 16 = 2416 parameters\n","    model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n","    # The input matrix size of this layer is 10 * 10 * 16. The size of the filter used in this layer is 2 * 2, and the length and width steps are both 2, so the output matrix size of this layer is 5 * 5 * 16.\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    # The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n","    # So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Flatten())\n","    model.add(Dense(120, activation='relu'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(84, activation='relu'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n","    return model\n","\n"],"metadata":{"id":"E-3CAcLUlr3X","executionInfo":{"status":"ok","timestamp":1698843354145,"user_tz":-360,"elapsed":11,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# building the model\n","model_2 = build_lenet_with_relu()\n","\n","model_2.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_2.evaluate(x_test, y_test)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hK2lnibio7b0","executionInfo":{"status":"ok","timestamp":1698843920969,"user_tz":-360,"elapsed":566833,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"6934d3e3-c32b-4469-b112-1168fe71e719"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 24, 24, 6)         156       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 12, 12, 6)         0         \n"," D)                                                              \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 16)          2416      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 4, 4, 16)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 256)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 120)               30840     \n","                                                                 \n"," dense_4 (Dense)             (None, 84)                10164     \n","                                                                 \n"," dense_5 (Dense)             (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 44426 (173.54 KB)\n","Trainable params: 44426 (173.54 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 28s 56ms/step - loss: 0.3246 - accuracy: 0.9027 - val_loss: 0.0989 - val_accuracy: 0.9692\n","Epoch 2/20\n","469/469 [==============================] - 27s 57ms/step - loss: 0.0892 - accuracy: 0.9725 - val_loss: 0.0525 - val_accuracy: 0.9829\n","Epoch 3/20\n","469/469 [==============================] - 27s 57ms/step - loss: 0.0630 - accuracy: 0.9806 - val_loss: 0.0458 - val_accuracy: 0.9856\n","Epoch 4/20\n","469/469 [==============================] - 27s 58ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.0396 - val_accuracy: 0.9879\n","Epoch 5/20\n","469/469 [==============================] - 27s 57ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.0350 - val_accuracy: 0.9897\n","Epoch 6/20\n","469/469 [==============================] - 27s 57ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 0.0334 - val_accuracy: 0.9885\n","Epoch 7/20\n","469/469 [==============================] - 26s 56ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0428 - val_accuracy: 0.9868\n","Epoch 8/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0298 - val_accuracy: 0.9897\n","Epoch 9/20\n","469/469 [==============================] - 26s 56ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0369 - val_accuracy: 0.9877\n","Epoch 10/20\n","469/469 [==============================] - 25s 54ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0321 - val_accuracy: 0.9901\n","Epoch 11/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0310 - val_accuracy: 0.9904\n","Epoch 12/20\n","469/469 [==============================] - 25s 53ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0397 - val_accuracy: 0.9889\n","Epoch 13/20\n","469/469 [==============================] - 24s 52ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0461 - val_accuracy: 0.9854\n","Epoch 14/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0337 - val_accuracy: 0.9903\n","Epoch 15/20\n","469/469 [==============================] - 26s 56ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0305 - val_accuracy: 0.9910\n","Epoch 16/20\n","469/469 [==============================] - 26s 56ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0358 - val_accuracy: 0.9903\n","Epoch 17/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0315 - val_accuracy: 0.9911\n","Epoch 18/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0438 - val_accuracy: 0.9883\n","Epoch 19/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0388 - val_accuracy: 0.9892\n","Epoch 20/20\n","469/469 [==============================] - 26s 55ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0379 - val_accuracy: 0.9900\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0379 - accuracy: 0.9900\n","Test Loss: 0.03794680908322334\n","Test accuracy: 0.9900000095367432\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zIGrR22wCbeN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_lenet_3_3():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=6,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=84, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(lr=0.1), metrics=['accuracy'])\n","    return model"],"metadata":{"id":"IMuCVgqrCbbo","executionInfo":{"status":"ok","timestamp":1698844848660,"user_tz":-360,"elapsed":459,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model_3 = build_lenet_3_3()\n","\n","model_3.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_3.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghS_Q8wbCbZB","executionInfo":{"status":"ok","timestamp":1698845257060,"user_tz":-360,"elapsed":407801,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"008c14b6-8b42-4c8e-d60b-1a93222aadc4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 26, 26, 6)         60        \n","                                                                 \n"," average_pooling2d_2 (Avera  (None, 13, 13, 6)         0         \n"," gePooling2D)                                                    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 11, 11, 16)        880       \n","                                                                 \n"," average_pooling2d_3 (Avera  (None, 5, 5, 16)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten_2 (Flatten)         (None, 400)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 128)               51328     \n","                                                                 \n"," dense_7 (Dense)             (None, 84)                10836     \n","                                                                 \n"," dense_8 (Dense)             (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 63954 (249.82 KB)\n","Trainable params: 63954 (249.82 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 21s 43ms/step - loss: 1.3456 - accuracy: 0.6519 - val_loss: 0.6431 - val_accuracy: 0.8510\n","Epoch 2/20\n","469/469 [==============================] - 19s 41ms/step - loss: 0.5269 - accuracy: 0.8658 - val_loss: 0.4333 - val_accuracy: 0.8834\n","Epoch 3/20\n","469/469 [==============================] - 23s 48ms/step - loss: 0.4073 - accuracy: 0.8872 - val_loss: 0.3631 - val_accuracy: 0.8969\n","Epoch 4/20\n","469/469 [==============================] - 20s 42ms/step - loss: 0.3550 - accuracy: 0.8985 - val_loss: 0.3233 - val_accuracy: 0.9050\n","Epoch 5/20\n","469/469 [==============================] - 20s 43ms/step - loss: 0.3223 - accuracy: 0.9063 - val_loss: 0.2946 - val_accuracy: 0.9144\n","Epoch 6/20\n","469/469 [==============================] - 18s 39ms/step - loss: 0.2977 - accuracy: 0.9128 - val_loss: 0.2727 - val_accuracy: 0.9197\n","Epoch 7/20\n","469/469 [==============================] - 19s 41ms/step - loss: 0.2777 - accuracy: 0.9187 - val_loss: 0.2551 - val_accuracy: 0.9251\n","Epoch 8/20\n","469/469 [==============================] - 18s 39ms/step - loss: 0.2604 - accuracy: 0.9239 - val_loss: 0.2391 - val_accuracy: 0.9297\n","Epoch 9/20\n","469/469 [==============================] - 23s 50ms/step - loss: 0.2451 - accuracy: 0.9276 - val_loss: 0.2255 - val_accuracy: 0.9340\n","Epoch 10/20\n","469/469 [==============================] - 22s 47ms/step - loss: 0.2312 - accuracy: 0.9315 - val_loss: 0.2122 - val_accuracy: 0.9377\n","Epoch 11/20\n","469/469 [==============================] - 19s 41ms/step - loss: 0.2187 - accuracy: 0.9356 - val_loss: 0.2007 - val_accuracy: 0.9416\n","Epoch 12/20\n","469/469 [==============================] - 20s 42ms/step - loss: 0.2073 - accuracy: 0.9384 - val_loss: 0.1904 - val_accuracy: 0.9453\n","Epoch 13/20\n","469/469 [==============================] - 19s 40ms/step - loss: 0.1968 - accuracy: 0.9418 - val_loss: 0.1803 - val_accuracy: 0.9488\n","Epoch 14/20\n","469/469 [==============================] - 21s 45ms/step - loss: 0.1871 - accuracy: 0.9455 - val_loss: 0.1717 - val_accuracy: 0.9505\n","Epoch 15/20\n","469/469 [==============================] - 20s 43ms/step - loss: 0.1782 - accuracy: 0.9480 - val_loss: 0.1629 - val_accuracy: 0.9524\n","Epoch 16/20\n","469/469 [==============================] - 21s 45ms/step - loss: 0.1701 - accuracy: 0.9503 - val_loss: 0.1562 - val_accuracy: 0.9544\n","Epoch 17/20\n","469/469 [==============================] - 20s 42ms/step - loss: 0.1626 - accuracy: 0.9529 - val_loss: 0.1504 - val_accuracy: 0.9567\n","Epoch 18/20\n","469/469 [==============================] - 20s 42ms/step - loss: 0.1558 - accuracy: 0.9548 - val_loss: 0.1437 - val_accuracy: 0.9584\n","Epoch 19/20\n","469/469 [==============================] - 20s 42ms/step - loss: 0.1494 - accuracy: 0.9570 - val_loss: 0.1378 - val_accuracy: 0.9602\n","Epoch 20/20\n","469/469 [==============================] - 20s 44ms/step - loss: 0.1436 - accuracy: 0.9586 - val_loss: 0.1330 - val_accuracy: 0.9612\n","313/313 [==============================] - 2s 6ms/step - loss: 0.1330 - accuracy: 0.9612\n","Test Loss: 0.13298684358596802\n","Test accuracy: 0.9611999988555908\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3e7BZ1GjCy6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oA2khkvuC6dy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_lenet_3_3_2():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=6,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","\n","    model.add(Conv2D(\n","        filters=6,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=84, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), metrics=['accuracy'])\n","    return model\n","\n","# Building model\n","model_4 = build_lenet_3_3_2()\n","\n","model_4.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_4.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNeI8l6QC6a_","executionInfo":{"status":"ok","timestamp":1698846117653,"user_tz":-360,"elapsed":808372,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"ca9f3f5a-7480-42f0-8d25-a1f149dc8ab9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 26, 26, 6)         60        \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 24, 24, 6)         330       \n","                                                                 \n"," average_pooling2d_4 (Avera  (None, 12, 12, 6)         0         \n"," gePooling2D)                                                    \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 10, 10, 16)        880       \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 8, 8, 16)          2320      \n","                                                                 \n"," average_pooling2d_5 (Avera  (None, 4, 4, 16)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten_3 (Flatten)         (None, 256)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dense_10 (Dense)            (None, 84)                10836     \n","                                                                 \n"," dense_11 (Dense)            (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 48172 (188.17 KB)\n","Trainable params: 48172 (188.17 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 39s 80ms/step - loss: 0.3870 - accuracy: 0.8896 - val_loss: 0.1785 - val_accuracy: 0.9473\n","Epoch 2/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.1420 - accuracy: 0.9581 - val_loss: 0.1046 - val_accuracy: 0.9682\n","Epoch 3/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0932 - accuracy: 0.9727 - val_loss: 0.0729 - val_accuracy: 0.9788\n","Epoch 4/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0718 - accuracy: 0.9783 - val_loss: 0.0615 - val_accuracy: 0.9815\n","Epoch 5/20\n","469/469 [==============================] - 37s 80ms/step - loss: 0.0598 - accuracy: 0.9820 - val_loss: 0.0567 - val_accuracy: 0.9828\n","Epoch 6/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0510 - accuracy: 0.9847 - val_loss: 0.0502 - val_accuracy: 0.9854\n","Epoch 7/20\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.0422 - val_accuracy: 0.9876\n","Epoch 8/20\n","469/469 [==============================] - 37s 80ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0410 - val_accuracy: 0.9878\n","Epoch 9/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0363 - accuracy: 0.9899 - val_loss: 0.0405 - val_accuracy: 0.9867\n","Epoch 10/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0336 - accuracy: 0.9901 - val_loss: 0.0360 - val_accuracy: 0.9882\n","Epoch 11/20\n","469/469 [==============================] - 38s 80ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.0340 - val_accuracy: 0.9887\n","Epoch 12/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.0338 - val_accuracy: 0.9885\n","Epoch 13/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.0343 - val_accuracy: 0.9888\n","Epoch 14/20\n","469/469 [==============================] - 40s 84ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0350 - val_accuracy: 0.9883\n","Epoch 15/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0314 - val_accuracy: 0.9894\n","Epoch 16/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.0304 - val_accuracy: 0.9896\n","Epoch 17/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0287 - val_accuracy: 0.9907\n","Epoch 18/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0313 - val_accuracy: 0.9901\n","Epoch 19/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.0283 - val_accuracy: 0.9905\n","Epoch 20/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0285 - val_accuracy: 0.9908\n","313/313 [==============================] - 3s 11ms/step - loss: 0.0285 - accuracy: 0.9908\n","Test Loss: 0.028459621593356133\n","Test accuracy: 0.9908000230789185\n"]}]},{"cell_type":"markdown","source":["# More filters"],"metadata":{"id":"_drfDKD3DEAI"}},{"cell_type":"code","source":["def build_lenet_filler_1():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=8,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=8,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    model.add(Conv2D(\n","        filters=32,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=84, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), metrics=['accuracy'])\n","    return model\n","\n","# Building model\n","model_5 = build_lenet_filler_1()\n","\n","model_5.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_5.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnQyo7XPDD2Q","executionInfo":{"status":"ok","timestamp":1698846924600,"user_tz":-360,"elapsed":806975,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"9476abe5-557d-46af-ea8b-16e95e91533e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_10 (Conv2D)          (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 24, 24, 8)         584       \n","                                                                 \n"," average_pooling2d_6 (Avera  (None, 12, 12, 8)         0         \n"," gePooling2D)                                                    \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 10, 10, 16)        1168      \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 8, 8, 32)          4640      \n","                                                                 \n"," average_pooling2d_7 (Avera  (None, 4, 4, 32)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten_4 (Flatten)         (None, 512)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 128)               65664     \n","                                                                 \n"," dense_13 (Dense)            (None, 84)                10836     \n","                                                                 \n"," dense_14 (Dense)            (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 83822 (327.43 KB)\n","Trainable params: 83822 (327.43 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 38s 78ms/step - loss: 0.3533 - accuracy: 0.8997 - val_loss: 0.1665 - val_accuracy: 0.9502\n","Epoch 2/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.1356 - accuracy: 0.9602 - val_loss: 0.0963 - val_accuracy: 0.9730\n","Epoch 3/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0899 - accuracy: 0.9735 - val_loss: 0.0755 - val_accuracy: 0.9785\n","Epoch 4/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0682 - accuracy: 0.9798 - val_loss: 0.0680 - val_accuracy: 0.9788\n","Epoch 5/20\n","469/469 [==============================] - 36s 78ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.0564 - val_accuracy: 0.9826\n","Epoch 6/20\n","469/469 [==============================] - 36s 76ms/step - loss: 0.0479 - accuracy: 0.9856 - val_loss: 0.0484 - val_accuracy: 0.9843\n","Epoch 7/20\n","469/469 [==============================] - 36s 77ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0480 - val_accuracy: 0.9844\n","Epoch 8/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0421 - val_accuracy: 0.9867\n","Epoch 9/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0442 - val_accuracy: 0.9870\n","Epoch 10/20\n","469/469 [==============================] - 36s 77ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9861\n","Epoch 11/20\n","469/469 [==============================] - 37s 80ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.0392 - val_accuracy: 0.9872\n","Epoch 12/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.0408 - val_accuracy: 0.9868\n","Epoch 13/20\n","469/469 [==============================] - 45s 95ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0382 - val_accuracy: 0.9880\n","Epoch 14/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0369 - val_accuracy: 0.9887\n","Epoch 15/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.0466 - val_accuracy: 0.9857\n","Epoch 16/20\n","469/469 [==============================] - 36s 76ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0362 - val_accuracy: 0.9886\n","Epoch 17/20\n","469/469 [==============================] - 36s 78ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0339 - val_accuracy: 0.9900\n","Epoch 18/20\n","469/469 [==============================] - 37s 80ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0348 - val_accuracy: 0.9884\n","Epoch 19/20\n","469/469 [==============================] - 37s 78ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0343 - val_accuracy: 0.9892\n","Epoch 20/20\n","469/469 [==============================] - 37s 80ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0403 - val_accuracy: 0.9875\n","313/313 [==============================] - 3s 10ms/step - loss: 0.0403 - accuracy: 0.9875\n","Test Loss: 0.04025387763977051\n","Test accuracy: 0.987500011920929\n"]}]},{"cell_type":"code","source":["def build_lenet_filler_1():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=8,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=8,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    model.add(Conv2D(\n","        filters=32,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=32,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=84, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), metrics=['accuracy'])\n","    return model\n","\n","# Building model\n","model_5 = build_lenet_filler_1()\n","\n","model_5.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_5.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RAW646gXDDy_","executionInfo":{"status":"ok","timestamp":1698847791634,"user_tz":-360,"elapsed":867041,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"0c614efd-3cd2-4f7e-f7c8-87728089044c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_14 (Conv2D)          (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_15 (Conv2D)          (None, 24, 24, 8)         584       \n","                                                                 \n"," average_pooling2d_8 (Avera  (None, 12, 12, 8)         0         \n"," gePooling2D)                                                    \n","                                                                 \n"," conv2d_16 (Conv2D)          (None, 10, 10, 16)        1168      \n","                                                                 \n"," conv2d_17 (Conv2D)          (None, 8, 8, 16)          2320      \n","                                                                 \n"," conv2d_18 (Conv2D)          (None, 6, 6, 32)          4640      \n","                                                                 \n"," conv2d_19 (Conv2D)          (None, 4, 4, 32)          9248      \n","                                                                 \n"," average_pooling2d_9 (Avera  (None, 2, 2, 32)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten_5 (Flatten)         (None, 128)               0         \n","                                                                 \n"," dense_15 (Dense)            (None, 128)               16512     \n","                                                                 \n"," dense_16 (Dense)            (None, 84)                10836     \n","                                                                 \n"," dense_17 (Dense)            (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 46238 (180.62 KB)\n","Trainable params: 46238 (180.62 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 43s 90ms/step - loss: 0.3811 - accuracy: 0.8904 - val_loss: 0.1462 - val_accuracy: 0.9571\n","Epoch 2/20\n","469/469 [==============================] - 41s 88ms/step - loss: 0.1272 - accuracy: 0.9615 - val_loss: 0.0917 - val_accuracy: 0.9733\n","Epoch 3/20\n","469/469 [==============================] - 41s 87ms/step - loss: 0.0862 - accuracy: 0.9740 - val_loss: 0.0679 - val_accuracy: 0.9797\n","Epoch 4/20\n","469/469 [==============================] - 41s 87ms/step - loss: 0.0677 - accuracy: 0.9795 - val_loss: 0.0534 - val_accuracy: 0.9836\n","Epoch 5/20\n","469/469 [==============================] - 41s 86ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0470 - val_accuracy: 0.9847\n","Epoch 6/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.0411 - val_accuracy: 0.9866\n","Epoch 7/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.0407 - val_accuracy: 0.9856\n","Epoch 8/20\n","469/469 [==============================] - 41s 87ms/step - loss: 0.0389 - accuracy: 0.9881 - val_loss: 0.0365 - val_accuracy: 0.9888\n","Epoch 9/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 0.0452 - val_accuracy: 0.9849\n","Epoch 10/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 0.0363 - val_accuracy: 0.9880\n","Epoch 11/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 0.0343 - val_accuracy: 0.9881\n","Epoch 12/20\n","469/469 [==============================] - 40s 84ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0364 - val_accuracy: 0.9889\n","Epoch 13/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0326 - val_accuracy: 0.9892\n","Epoch 14/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0332 - val_accuracy: 0.9895\n","Epoch 15/20\n","469/469 [==============================] - 41s 87ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0336 - val_accuracy: 0.9889\n","Epoch 16/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0298 - val_accuracy: 0.9895\n","Epoch 17/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.0328 - val_accuracy: 0.9889\n","Epoch 18/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0302 - val_accuracy: 0.9906\n","Epoch 19/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0286 - val_accuracy: 0.9916\n","Epoch 20/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0333 - val_accuracy: 0.9896\n","313/313 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9896\n","Test Loss: 0.03325819969177246\n","Test accuracy: 0.9896000027656555\n"]}]},{"cell_type":"markdown","source":["# More dense Unit"],"metadata":{"id":"5KQb8-knDIoD"}},{"cell_type":"code","source":["def build_lenet_more_dense():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=6,\n","        kernel_size = (5,5),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (5,5),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=64, activation='tanh'))\n","    model.add(Dense(units=32, activation='tanh'))\n","    model.add(Dense(units=16, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(lr=0.1), metrics=['accuracy'])\n","    return model\n","\n","\n","# Building model\n","model_6 = build_lenet_filler_1()\n","\n","model_6.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_6.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5UVxjGaJJyR","outputId":"c0a82bb2-f4fb-4ace-a1f4-8c7f75f29892"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_20 (Conv2D)          (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_21 (Conv2D)          (None, 24, 24, 8)         584       \n","                                                                 \n"," average_pooling2d_10 (Aver  (None, 12, 12, 8)         0         \n"," agePooling2D)                                                   \n","                                                                 \n"," conv2d_22 (Conv2D)          (None, 10, 10, 16)        1168      \n","                                                                 \n"," conv2d_23 (Conv2D)          (None, 8, 8, 16)          2320      \n","                                                                 \n"," conv2d_24 (Conv2D)          (None, 6, 6, 32)          4640      \n","                                                                 \n"," conv2d_25 (Conv2D)          (None, 4, 4, 32)          9248      \n","                                                                 \n"," average_pooling2d_11 (Aver  (None, 2, 2, 32)          0         \n"," agePooling2D)                                                   \n","                                                                 \n"," flatten_6 (Flatten)         (None, 128)               0         \n","                                                                 \n"," dense_18 (Dense)            (None, 128)               16512     \n","                                                                 \n"," dense_19 (Dense)            (None, 84)                10836     \n","                                                                 \n"," dense_20 (Dense)            (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 46238 (180.62 KB)\n","Trainable params: 46238 (180.62 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 39s 81ms/step - loss: 0.3880 - accuracy: 0.8883 - val_loss: 0.1544 - val_accuracy: 0.9535\n","Epoch 2/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.1271 - accuracy: 0.9617 - val_loss: 0.0898 - val_accuracy: 0.9724\n","Epoch 3/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0860 - accuracy: 0.9742 - val_loss: 0.0676 - val_accuracy: 0.9792\n","Epoch 4/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0680 - accuracy: 0.9793 - val_loss: 0.0532 - val_accuracy: 0.9832\n","Epoch 5/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0563 - accuracy: 0.9832 - val_loss: 0.0497 - val_accuracy: 0.9837\n","Epoch 6/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.0483 - val_accuracy: 0.9832\n","Epoch 7/20\n","469/469 [==============================] - 39s 82ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0400 - val_accuracy: 0.9860\n","Epoch 8/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.0396 - val_accuracy: 0.9876\n","Epoch 9/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0365 - val_accuracy: 0.9868\n","Epoch 10/20\n","469/469 [==============================] - 36s 78ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0371 - val_accuracy: 0.9876\n","Epoch 11/20\n","469/469 [==============================] - 37s 80ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 0.0355 - val_accuracy: 0.9886\n","Epoch 12/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0332 - val_accuracy: 0.9893\n","Epoch 13/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0323 - val_accuracy: 0.9898\n","Epoch 14/20\n","469/469 [==============================] - 36s 77ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0306 - val_accuracy: 0.9902\n","Epoch 15/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0334 - val_accuracy: 0.9888\n","Epoch 16/20\n","469/469 [==============================] - 40s 84ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0305 - val_accuracy: 0.9901\n","Epoch 17/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0321 - val_accuracy: 0.9893\n","Epoch 18/20\n","307/469 [==================>...........] - ETA: 12s - loss: 0.0148 - accuracy: 0.9956"]}]},{"cell_type":"code","source":["def build_lenet_filler_1():\n","    model = Sequential()\n","    # Conv-1: Filter as we know 6, filter_size= 5 x 5, 'tanh' is the activation and input size is 28 X 28 grayscap images\n","    model.add(Conv2D(\n","        filters=8,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=8,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh',\n","        input_shape=(28, 28, 1)\n","        )\n","    )\n","\n","    # Subsampling-1: input for this layer (28 x 28 x 6) Output= (14 x 14 x 6)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Conv-2: input for this layer (14 x 14 x 6) Output= (10 x 10 x 16)\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=16,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    model.add(Conv2D(\n","        filters=32,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","    model.add(Conv2D(\n","        filters=32,\n","        kernel_size = (3,3),\n","        strides=(1,1),\n","        activation='tanh'\n","        )\n","    )\n","\n","    # Subsampling-2: input for this layer (10 x 10 x 16) Output= (5 x 5 x 16)\n","    model.add(\n","        AveragePooling2D(\n","            pool_size=(2,2),\n","            strides=(2,2)\n","        )\n","    )\n","    # Flatten: here 5 * 5 * 16 matrix  pulled into a vector\n","\n","    model.add(Flatten())\n","    # The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n","    model.add(Dense(units=128, activation='tanh'))\n","    # The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n","    model.add(Dense(units=64, activation='tanh'))\n","    model.add(Dense(units=32, activation='tanh'))\n","    model.add(Dense(units=12, activation='tanh'))\n","    # The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n","    model.add(Dense(units=10, activation='softmax'))\n","\n","    model.summary()\n","    model.compile(loss=tf.keras.metrics.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), metrics=['accuracy'])\n","    return model\n","\n","# Building model\n","model_7 = build_lenet_filler_1()\n","\n","model_7.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n","score = model_7.evaluate(x_test, y_test, verbose=1)\n","print('Test Loss:', score[0])\n","print('Test accuracy:', score[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0Tr-zd5DYY4","executionInfo":{"status":"ok","timestamp":1698850220345,"user_tz":-360,"elapsed":232458,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"1fb75b72-9ebd-4ae2-99d7-c2872fa44369"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_26 (Conv2D)          (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_27 (Conv2D)          (None, 24, 24, 8)         584       \n","                                                                 \n"," average_pooling2d_12 (Aver  (None, 12, 12, 8)         0         \n"," agePooling2D)                                                   \n","                                                                 \n"," conv2d_28 (Conv2D)          (None, 10, 10, 16)        1168      \n","                                                                 \n"," conv2d_29 (Conv2D)          (None, 8, 8, 16)          2320      \n","                                                                 \n"," conv2d_30 (Conv2D)          (None, 6, 6, 32)          4640      \n","                                                                 \n"," conv2d_31 (Conv2D)          (None, 4, 4, 32)          9248      \n","                                                                 \n"," average_pooling2d_13 (Aver  (None, 2, 2, 32)          0         \n"," agePooling2D)                                                   \n","                                                                 \n"," flatten_7 (Flatten)         (None, 128)               0         \n","                                                                 \n"," dense_21 (Dense)            (None, 128)               16512     \n","                                                                 \n"," dense_22 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_23 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dense_24 (Dense)            (None, 12)                396       \n","                                                                 \n"," dense_25 (Dense)            (None, 10)                130       \n","                                                                 \n","=================================================================\n","Total params: 45414 (177.40 KB)\n","Trainable params: 45414 (177.40 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 40s 83ms/step - loss: 0.5631 - accuracy: 0.8513 - val_loss: 0.2055 - val_accuracy: 0.9468\n","Epoch 2/20\n","469/469 [==============================] - 38s 80ms/step - loss: 0.1529 - accuracy: 0.9597 - val_loss: 0.0946 - val_accuracy: 0.9749\n","Epoch 3/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0998 - accuracy: 0.9728 - val_loss: 0.0823 - val_accuracy: 0.9783\n","Epoch 4/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0760 - accuracy: 0.9793 - val_loss: 0.0733 - val_accuracy: 0.9792\n","Epoch 5/20\n","469/469 [==============================] - 37s 79ms/step - loss: 0.0626 - accuracy: 0.9826 - val_loss: 0.0572 - val_accuracy: 0.9836\n","Epoch 6/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0534 - accuracy: 0.9855 - val_loss: 0.0538 - val_accuracy: 0.9852\n","Epoch 7/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.0551 - val_accuracy: 0.9844\n","Epoch 8/20\n","469/469 [==============================] - 40s 84ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.0481 - val_accuracy: 0.9854\n","Epoch 9/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.0452 - val_accuracy: 0.9874\n","Epoch 10/20\n","469/469 [==============================] - 39s 83ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0438 - val_accuracy: 0.9879\n","Epoch 11/20\n","469/469 [==============================] - 40s 85ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 0.0394 - val_accuracy: 0.9892\n","Epoch 12/20\n","469/469 [==============================] - 38s 82ms/step - loss: 0.0262 - accuracy: 0.9929 - val_loss: 0.0388 - val_accuracy: 0.9885\n","Epoch 13/20\n","469/469 [==============================] - 40s 84ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.0408 - val_accuracy: 0.9885\n","Epoch 14/20\n","469/469 [==============================] - 38s 81ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0361 - val_accuracy: 0.9901\n","Epoch 15/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.0441 - val_accuracy: 0.9886\n","Epoch 16/20\n","469/469 [==============================] - 39s 84ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.0433 - val_accuracy: 0.9885\n","Epoch 17/20\n","469/469 [==============================] - 41s 88ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0360 - val_accuracy: 0.9910\n","Epoch 18/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0353 - val_accuracy: 0.9900\n","Epoch 19/20\n","469/469 [==============================] - 40s 86ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0389 - val_accuracy: 0.9890\n","Epoch 20/20\n","469/469 [==============================] - 41s 87ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0393 - val_accuracy: 0.9896\n","313/313 [==============================] - 4s 12ms/step - loss: 0.0393 - accuracy: 0.9896\n","Test Loss: 0.03932470828294754\n","Test accuracy: 0.9896000027656555\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9YZEN-uXDYeW","executionInfo":{"status":"ok","timestamp":1698850220346,"user_tz":-360,"elapsed":3,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":17,"outputs":[]}]}