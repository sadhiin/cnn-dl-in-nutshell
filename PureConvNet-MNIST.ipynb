{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Phzp6QWO_6F_"],"authorship_tag":"ABX9TyN5ldpMAbTXJfdnQDIqsxut"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Objective\n","- Pure CNN Network\n","- Lenss then 10,000 trainable perameters\n","- Accuracy more then **99.40%**"],"metadata":{"id":"kpqWNt4k5M09"}},{"cell_type":"markdown","source":["# Improting nessary Libary"],"metadata":{"id":"kDrQ3VJo5eY0"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"gGMU7GgR3ihu","executionInfo":{"status":"ok","timestamp":1699002173299,"user_tz":-360,"elapsed":4,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","\n","# importing the mnist dataset from tensorflow.keras.datasets\n","from tensorflow.keras.datasets import mnist"]},{"cell_type":"code","source":["# we are downloading the MNIST dataset and splitting the data for training and testing\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{"id":"jVZL7ykL4M08","executionInfo":{"status":"ok","timestamp":1699002174216,"user_tz":-360,"elapsed":921,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5d29769-295d-4791-8825-e4c865fcd8f2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["print (X_train.shape)\n","\n","plt.imshow(X_train[0])\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"mydMWCSg4Myc","executionInfo":{"status":"ok","timestamp":1699002174217,"user_tz":-360,"elapsed":7,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"22dd9f33-1d40-471b-dec1-8ffadc4f2741"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["#Reshaping our training and testing datatset using numpy's reshape function which we will feed to the model\n","X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"],"metadata":{"id":"hSBQF2MU4Mvv","executionInfo":{"status":"ok","timestamp":1699002174217,"user_tz":-360,"elapsed":5,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Doing type conversion or changing the datatype to float32 for the data\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","#Doing standardization or normalization here dividind each pixel by 255 in the train and test data\n","X_train /= 255.0\n","X_test /= 255.0"],"metadata":{"id":"4obYBctD4MtJ","executionInfo":{"status":"ok","timestamp":1699002175356,"user_tz":-360,"elapsed":1144,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Checking first 10 image labels\n","y_train[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyWRi4hl4YS0","executionInfo":{"status":"ok","timestamp":1699002175356,"user_tz":-360,"elapsed":6,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"9025e82b-4edf-44d9-9342-228d804ea434"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Convert 1-dimensional class arrays to 10-dimensional class matrices\n","# simply we can say we are doing sort of onehot encoding\n","Y_train = to_categorical(y_train, 10)\n","Y_test = to_categorical(y_test, 10)"],"metadata":{"id":"RktVkX0g6fSm","executionInfo":{"status":"ok","timestamp":1699002175356,"user_tz":-360,"elapsed":4,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","# having a look in the first 10 datapoints after onehot encoding\n","Y_train[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cL8IpfK6fPq","executionInfo":{"status":"ok","timestamp":1699002175356,"user_tz":-360,"elapsed":4,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"3a720b1b-c2ca-4f22-8005-bd3d6f04c935"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Given Model"],"metadata":{"id":"AiqFeqdW_3n5"}},{"cell_type":"code","source":["def given_model():\n","    # building our sequential model using the Sequential class and creating the model object\n","    model = Sequential()\n","    # Performing 2dconvolution followed by BatchNormalization and Dropout\n","    model.add(Conv2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))  # channel dimensions = 26x26x10    and Receptive field = 3x3\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))\n","\n","    # Performing 2dconvolution followed by BatchNormalization and Dropout\n","    model.add(Conv2D(16, 3, 3, activation='relu'))                        # channel dimensions = 24x24x16    and Receptive field = 5x5\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))\n","\n","    # Performing 2dconvolution followed Maxpoooling operation\n","    model.add(Conv2D(10, 1, 1, activation='relu'))   #24                  # channel dimensions = 24x24x10    and Receptive field = 7x7 using 1x1 kernel\n","    model.add(MaxPooling2D(pool_size=(2, 2)))       #12                                 # channel dimensions = 12x12x10    and Receptive field = 14x14\n","\n","    # Performing 2dconvolution followed by BatchNormalization and Dropout\n","    model.add(Conv2D(16, 3, 3, activation='relu'))#10                     # channel dimensions = 10x10x16    and Receptive field = 16x16\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))\n","\n","    # Performing 2dconvolution followed by BatchNormalization and Dropout\n","    model.add(Conv2D(16, 3, 3, activation='relu'))#8                      # channel dimensions = 8x8x16    and Receptive field = 18x18\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))\n","\n","    # Performing 2dconvolution followed by BatchNormalization and Dropout\n","    model.add(Conv2D(16, 3, 3, activation='relu'))#6                      # channel dimensions = 6x6x16    and Receptive field = 20x20\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))\n","\n","    # Performing 2dconvolution followed by BatchNormalization and Dropout\n","    model.add(Conv2D(16, 3, 3, activation='relu'))#4                      # channel dimensions = 4x4x16    and Receptive field = 22x22\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))\n","\n","    # Performing only 2dconvolution at the last convolution layer(no batchnormalization and dropout)\n","    model.add(Conv2D(10, 4, 4))                                           # using 4x4 kernel to see the complete image\n","\n","    # Here we are Flateening our dat i.e making it one dimensional which we will feed to the network.\n","    model.add(Flatten())\n","    #Using softmax activation function at the last layer which is used for multi class classification\n","    model.add(Activation('softmax'))\n","    return model\n"],"metadata":{"id":"1fPo79Pu47Yq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = given_model()\n","model.summary()"],"metadata":{"id":"_JYPtbH249XN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Dropout, MaxPooling2D, Flatten, Activation"],"metadata":{"id":"CkV8KhxhWmXf","executionInfo":{"status":"ok","timestamp":1699002188615,"user_tz":-360,"elapsed":2,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Modification of given model"],"metadata":{"id":"Phzp6QWO_6F_"}},{"cell_type":"code","source":["\n","\n","# Initialize the model\n","model = Sequential()\n","\n","# Layer 1\n","model.add(Conv2D(10, kernel_size=(3,3), input_shape=(28,28,1), name=\"conv2d_1\"))\n","model.add(BatchNormalization(name=\"batch_normalization_1\"))\n","model.add(Dropout(0.1, name=\"dropout_1\"))\n","\n","# Layer 2\n","model.add(Conv2D(16, kernel_size=(3,3), name=\"conv2d_2\"))\n","model.add(BatchNormalization(name=\"batch_normalization_2\"))\n","model.add(Dropout(0.1, name=\"dropout_2\"))\n","\n","# Layer 3\n","model.add(Conv2D(10, kernel_size=(1,1), name=\"conv2d_3\"))\n","model.add(MaxPooling2D(pool_size=(2,2), name=\"max_pooling2d_1\"))\n","\n","# Layer 4\n","model.add(Conv2D(16, kernel_size=(3,3), name=\"conv2d_4\"))\n","model.add(BatchNormalization(name=\"batch_normalization_3\"))\n","model.add(Dropout(0.1, name=\"dropout_3\"))\n","\n","# Layer 5\n","model.add(Conv2D(16, kernel_size=(3,3), name=\"conv2d_5\"))\n","model.add(BatchNormalization(name=\"batch_normalization_4\"))\n","model.add(Dropout(0.1, name=\"dropout_4\"))\n","\n","# Layer 6\n","model.add(Conv2D(16, kernel_size=(3,3), name=\"conv2d_6\"))\n","model.add(BatchNormalization(name=\"batch_normalization_5\"))\n","model.add(Dropout(0.1, name=\"dropout_5\"))\n","\n","# Layer 7\n","model.add(Conv2D(16, kernel_size=(3,3), name=\"conv2d_7\"))\n","model.add(BatchNormalization(name=\"batch_normalization_6\"))\n","model.add(Dropout(0.1, name=\"dropout_6\"))\n","\n","# Layer 8\n","model.add(Conv2D(10, kernel_size=(4,4), name=\"conv2d_8\"))\n","\n","# Flatten and Activation\n","model.add(Flatten(name=\"flatten_1\"))\n","model.add(Activation('softmax', name=\"activation_1\"))\n","\n","\n","# Print the model summary to check\n","model.summary()\n"],"metadata":{"id":"jXdJZE8C8WTt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"w7DVOzyhAQ0N"}},{"cell_type":"code","source":["# We are importing the Adam Optimizer\n","from tensorflow.keras.optimizers import Adam\n","\n","# We are importing the learningratescheduler callback\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","#Creating the \"scheduler\" function with two arguments i.e learningrate and epoch\n","def scheduler(epoch, lr):\n","  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n","\n","#\tLearningRate = LearningRate * 1/(1 + decay * epoch) here decay is 0.319 and epoch is 10.\n","\n","# here we are compiling our model and using 'categorical_crossentropy' as our loss function and adam as our optimizer with learning rate =0.003 and metrics is accuracy\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.003), metrics=['accuracy'])\n","\n","# Here we are traing our model using the data and using batch size of 128,number of epochs are 20 and using verbose=1 for printing out all the results.\n","# In the callbacks parameter we are using the LearningRateScheduler which takes two arguments scheduler function which we built earlier to reduce the learning rate in each decay and verbose =1\n","model.fit(X_train, Y_train,\n","          batch_size=128, epochs=20,\n","          verbose=1,\n","          validation_data=(X_test, Y_test),\n","          callbacks=[LearningRateScheduler(scheduler, verbose=1)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Avu5CdCe5Gj4","executionInfo":{"status":"ok","timestamp":1698912986996,"user_tz":-360,"elapsed":1589773,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"d8c947ee-a0c1-473f-802b-86ead20ce314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n","Epoch 1/20\n","469/469 [==============================] - 88s 183ms/step - loss: 0.2759 - accuracy: 0.9137 - val_loss: 0.2919 - val_accuracy: 0.9068 - lr: 0.0030\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.0022744503.\n","Epoch 2/20\n","469/469 [==============================] - 78s 167ms/step - loss: 0.1245 - accuracy: 0.9612 - val_loss: 0.0927 - val_accuracy: 0.9729 - lr: 0.0023\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.0018315018.\n","Epoch 3/20\n","469/469 [==============================] - 77s 164ms/step - loss: 0.1093 - accuracy: 0.9662 - val_loss: 0.0726 - val_accuracy: 0.9758 - lr: 0.0018\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 0.0015329586.\n","Epoch 4/20\n","469/469 [==============================] - 78s 165ms/step - loss: 0.1001 - accuracy: 0.9690 - val_loss: 0.0838 - val_accuracy: 0.9739 - lr: 0.0015\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 0.0013181019.\n","Epoch 5/20\n","469/469 [==============================] - 88s 188ms/step - loss: 0.0953 - accuracy: 0.9703 - val_loss: 0.0673 - val_accuracy: 0.9801 - lr: 0.0013\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 0.0011560694.\n","Epoch 6/20\n","469/469 [==============================] - 89s 191ms/step - loss: 0.0916 - accuracy: 0.9721 - val_loss: 0.0757 - val_accuracy: 0.9776 - lr: 0.0012\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 0.0010295127.\n","Epoch 7/20\n","469/469 [==============================] - 78s 166ms/step - loss: 0.0858 - accuracy: 0.9731 - val_loss: 0.0764 - val_accuracy: 0.9763 - lr: 0.0010\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 0.0009279307.\n","Epoch 8/20\n","469/469 [==============================] - 78s 166ms/step - loss: 0.0854 - accuracy: 0.9732 - val_loss: 0.0699 - val_accuracy: 0.9772 - lr: 9.2793e-04\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 0.0008445946.\n","Epoch 9/20\n","469/469 [==============================] - 80s 170ms/step - loss: 0.0834 - accuracy: 0.9745 - val_loss: 0.0649 - val_accuracy: 0.9794 - lr: 8.4459e-04\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 0.0007749935.\n","Epoch 10/20\n","469/469 [==============================] - 77s 163ms/step - loss: 0.0814 - accuracy: 0.9748 - val_loss: 0.0674 - val_accuracy: 0.9785 - lr: 7.7499e-04\n","\n","Epoch 11: LearningRateScheduler setting learning rate to 0.0007159905.\n","Epoch 11/20\n","469/469 [==============================] - 76s 163ms/step - loss: 0.0798 - accuracy: 0.9749 - val_loss: 0.0634 - val_accuracy: 0.9808 - lr: 7.1599e-04\n","\n","Epoch 12: LearningRateScheduler setting learning rate to 0.000665336.\n","Epoch 12/20\n","469/469 [==============================] - 76s 163ms/step - loss: 0.0769 - accuracy: 0.9770 - val_loss: 0.0578 - val_accuracy: 0.9823 - lr: 6.6534e-04\n","\n","Epoch 13: LearningRateScheduler setting learning rate to 0.0006213753.\n","Epoch 13/20\n","469/469 [==============================] - 78s 166ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: 0.0674 - val_accuracy: 0.9797 - lr: 6.2138e-04\n","\n","Epoch 14: LearningRateScheduler setting learning rate to 0.0005828638.\n","Epoch 14/20\n","469/469 [==============================] - 80s 170ms/step - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.0579 - val_accuracy: 0.9814 - lr: 5.8286e-04\n","\n","Epoch 15: LearningRateScheduler setting learning rate to 0.0005488474.\n","Epoch 15/20\n","469/469 [==============================] - 76s 163ms/step - loss: 0.0729 - accuracy: 0.9778 - val_loss: 0.0532 - val_accuracy: 0.9834 - lr: 5.4885e-04\n","\n","Epoch 16: LearningRateScheduler setting learning rate to 0.0005185825.\n","Epoch 16/20\n","469/469 [==============================] - 80s 170ms/step - loss: 0.0743 - accuracy: 0.9765 - val_loss: 0.0656 - val_accuracy: 0.9796 - lr: 5.1858e-04\n","\n","Epoch 17: LearningRateScheduler setting learning rate to 0.000491481.\n","Epoch 17/20\n","469/469 [==============================] - 79s 168ms/step - loss: 0.0731 - accuracy: 0.9773 - val_loss: 0.0555 - val_accuracy: 0.9832 - lr: 4.9148e-04\n","\n","Epoch 18: LearningRateScheduler setting learning rate to 0.0004670715.\n","Epoch 18/20\n","469/469 [==============================] - 78s 165ms/step - loss: 0.0735 - accuracy: 0.9770 - val_loss: 0.0557 - val_accuracy: 0.9813 - lr: 4.6707e-04\n","\n","Epoch 19: LearningRateScheduler setting learning rate to 0.0004449718.\n","Epoch 19/20\n","469/469 [==============================] - 77s 165ms/step - loss: 0.0710 - accuracy: 0.9774 - val_loss: 0.0560 - val_accuracy: 0.9832 - lr: 4.4497e-04\n","\n","Epoch 20: LearningRateScheduler setting learning rate to 0.000424869.\n","Epoch 20/20\n","469/469 [==============================] - 78s 167ms/step - loss: 0.0696 - accuracy: 0.9778 - val_loss: 0.0617 - val_accuracy: 0.9802 - lr: 4.2487e-04\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ef979c1f910>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkXBDge15Ghg","executionInfo":{"status":"ok","timestamp":1698912990996,"user_tz":-360,"elapsed":4005,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"0eea1188-0787-4bed-8d37-e15be2bc6f93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 4s 13ms/step - loss: 0.0617 - accuracy: 0.9802\n"]}]},{"cell_type":"code","source":["#Finally we are doing the predictions\n","y_pred = model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9gJuquo5Gen","executionInfo":{"status":"ok","timestamp":1698912995184,"user_tz":-360,"elapsed":4200,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"f207871c-7f56-4703-fa87-482c18a945fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 4s 11ms/step\n"]}]},{"cell_type":"code","source":["# Showing the results of predictions\n","for val in y_pred[:9]:\n","    print(np.argmax(val), end=\" \")\n","print()\n","print(y_test[:9])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"di9s1IOF5Gby","executionInfo":{"status":"ok","timestamp":1698913426183,"user_tz":-360,"elapsed":7,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"3eea0969-119b-4b8f-ccb2-55a6c2ff300d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7 2 1 0 4 1 4 9 5 \n","[7 2 1 0 4 1 4 9 5]\n"]}]},{"cell_type":"markdown","source":["# Less Training Paremeters"],"metadata":{"id":"va9WjZ28CHjA"}},{"cell_type":"code","source":["model_opt = Sequential()\n","\n","model_opt.add(Conv2D(8, kernel_size=(5,5), input_shape=(28,28,1)))\n","model_opt.add(BatchNormalization())\n","model_opt.add(Dropout(0.1))\n","\n","# model_opt.add(Conv2D(8, kernel_size=(3,3)))\n","# model_opt.add(BatchNormalization())\n","# model_opt.add(Dropout(0.1))\n","\n","model_opt.add(Conv2D(10, kernel_size=(1,1)))\n","model_opt.add(MaxPooling2D(pool_size=(2,2)))\n","\n","# model_opt.add(Conv2D(8, kernel_size=(3,3)))\n","# model_opt.add(BatchNormalization())\n","# model_opt.add(Dropout(0.1))\n","\n","model_opt.add(Conv2D(16, kernel_size=(5,5)))\n","model_opt.add(BatchNormalization())\n","model_opt.add(Dropout(0.1))\n","\n","# model_opt.add(Conv2D(16, kernel_size=(3,3)))\n","# model_opt.add(BatchNormalization())\n","# model_opt.add(Dropout(0.1))\n","\n","# model_opt.add(Conv2D(16, kernel_size=(5,5)))\n","# model_opt.add(BatchNormalization())\n","# model_opt.add(Dropout(0.1))\n","\n","model_opt.add(Conv2D(8, kernel_size=(5,5)))\n","model_opt.add(BatchNormalization())\n","model_opt.add(Dropout(0.1))\n","\n","# model_opt.add(Conv2D(8, kernel_size=(3,3)))\n","# model_opt.add(BatchNormalization())\n","# model_opt.add(Dropout(0.1))\n","\n","model_opt.add(Conv2D(10, kernel_size=(4,4)))\n","\n","# Flatten and Activation\n","model_opt.add(Flatten())\n","model_opt.add(Activation('softmax'))\n","\n","\n","# Print the model_opt summary to check\n","model_opt.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27MB-7wSCPje","executionInfo":{"status":"ok","timestamp":1699006517417,"user_tz":-360,"elapsed":717,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"1cbb2d76-18fb-46b0-bd82-4eac3a5f2870"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_79 (Conv2D)          (None, 24, 24, 8)         208       \n","                                                                 \n"," batch_normalization_49 (Ba  (None, 24, 24, 8)         32        \n"," tchNormalization)                                               \n","                                                                 \n"," dropout_49 (Dropout)        (None, 24, 24, 8)         0         \n","                                                                 \n"," conv2d_80 (Conv2D)          (None, 24, 24, 10)        90        \n","                                                                 \n"," max_pooling2d_15 (MaxPooli  (None, 12, 12, 10)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_81 (Conv2D)          (None, 8, 8, 16)          4016      \n","                                                                 \n"," batch_normalization_50 (Ba  (None, 8, 8, 16)          64        \n"," tchNormalization)                                               \n","                                                                 \n"," dropout_50 (Dropout)        (None, 8, 8, 16)          0         \n","                                                                 \n"," conv2d_82 (Conv2D)          (None, 4, 4, 8)           3208      \n","                                                                 \n"," batch_normalization_51 (Ba  (None, 4, 4, 8)           32        \n"," tchNormalization)                                               \n","                                                                 \n"," dropout_51 (Dropout)        (None, 4, 4, 8)           0         \n","                                                                 \n"," conv2d_83 (Conv2D)          (None, 1, 1, 10)          1290      \n","                                                                 \n"," flatten_12 (Flatten)        (None, 10)                0         \n","                                                                 \n"," activation_12 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 8940 (34.92 KB)\n","Trainable params: 8876 (34.67 KB)\n","Non-trainable params: 64 (256.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# We are importing the Adam Optimizer\n","from tensorflow.keras.optimizers import Adam\n","\n","# We are importing the learningratescheduler callback\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","#Creating the \"scheduler\" function with two arguments i.e learningrate and epoch\n","def scheduler(epoch, lr):\n","  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n","\n","#\tLearningRate = LearningRate * 1/(1 + decay * epoch) here decay is 0.319 and epoch is 10.\n","\n","# here we are compiling our model and using 'categorical_crossentropy' as our loss function and adam as our optimizer with learning rate =0.003 and metrics is accuracy\n","model_opt.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.003), metrics=['accuracy'])\n","\n","# Here we are traing our model using the data and using batch size of 128,number of epochs are 20 and using verbose=1 for printing out all the results.\n","# In the callbacks parameter we are using the LearningRateScheduler which takes two arguments scheduler function which we built earlier to reduce the learning rate in each decay and verbose =1\n","model_opt.fit(X_train, Y_train,\n","          batch_size=128, epochs=20,\n","          verbose=1,\n","          validation_data=(X_test, Y_test),\n","          callbacks=[LearningRateScheduler(scheduler, verbose=1)]\n","          )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSG9reOgCPoH","executionInfo":{"status":"ok","timestamp":1699007487756,"user_tz":-360,"elapsed":966739,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"277668e6-115e-466a-fa85-5a7f30ef10aa"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n","Epoch 1/20\n","469/469 [==============================] - 51s 103ms/step - loss: 0.2967 - accuracy: 0.9098 - val_loss: 0.1232 - val_accuracy: 0.9611 - lr: 0.0030\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.0022744503.\n","Epoch 2/20\n","469/469 [==============================] - 50s 107ms/step - loss: 0.1207 - accuracy: 0.9630 - val_loss: 0.1101 - val_accuracy: 0.9664 - lr: 0.0023\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.0018315018.\n","Epoch 3/20\n","469/469 [==============================] - 48s 102ms/step - loss: 0.1020 - accuracy: 0.9686 - val_loss: 0.1124 - val_accuracy: 0.9652 - lr: 0.0018\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 0.0015329586.\n","Epoch 4/20\n","469/469 [==============================] - 47s 101ms/step - loss: 0.0925 - accuracy: 0.9713 - val_loss: 0.0785 - val_accuracy: 0.9757 - lr: 0.0015\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 0.0013181019.\n","Epoch 5/20\n","469/469 [==============================] - 47s 101ms/step - loss: 0.0864 - accuracy: 0.9733 - val_loss: 0.0782 - val_accuracy: 0.9747 - lr: 0.0013\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 0.0011560694.\n","Epoch 6/20\n","469/469 [==============================] - 47s 101ms/step - loss: 0.0832 - accuracy: 0.9744 - val_loss: 0.0600 - val_accuracy: 0.9801 - lr: 0.0012\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 0.0010295127.\n","Epoch 7/20\n","469/469 [==============================] - 47s 99ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.0722 - val_accuracy: 0.9770 - lr: 0.0010\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 0.0009279307.\n","Epoch 8/20\n","469/469 [==============================] - 50s 108ms/step - loss: 0.0768 - accuracy: 0.9764 - val_loss: 0.0601 - val_accuracy: 0.9803 - lr: 9.2793e-04\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 0.0008445946.\n","Epoch 9/20\n","469/469 [==============================] - 48s 103ms/step - loss: 0.0737 - accuracy: 0.9773 - val_loss: 0.0715 - val_accuracy: 0.9776 - lr: 8.4459e-04\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 0.0007749935.\n","Epoch 10/20\n","469/469 [==============================] - 48s 101ms/step - loss: 0.0735 - accuracy: 0.9769 - val_loss: 0.0550 - val_accuracy: 0.9825 - lr: 7.7499e-04\n","\n","Epoch 11: LearningRateScheduler setting learning rate to 0.0007159905.\n","Epoch 11/20\n","469/469 [==============================] - 49s 104ms/step - loss: 0.0723 - accuracy: 0.9776 - val_loss: 0.0620 - val_accuracy: 0.9810 - lr: 7.1599e-04\n","\n","Epoch 12: LearningRateScheduler setting learning rate to 0.000665336.\n","Epoch 12/20\n","469/469 [==============================] - 48s 102ms/step - loss: 0.0695 - accuracy: 0.9783 - val_loss: 0.0568 - val_accuracy: 0.9812 - lr: 6.6534e-04\n","\n","Epoch 13: LearningRateScheduler setting learning rate to 0.0006213753.\n","Epoch 13/20\n","469/469 [==============================] - 47s 100ms/step - loss: 0.0698 - accuracy: 0.9785 - val_loss: 0.0538 - val_accuracy: 0.9827 - lr: 6.2138e-04\n","\n","Epoch 14: LearningRateScheduler setting learning rate to 0.0005828638.\n","Epoch 14/20\n","469/469 [==============================] - 49s 105ms/step - loss: 0.0680 - accuracy: 0.9790 - val_loss: 0.0546 - val_accuracy: 0.9833 - lr: 5.8286e-04\n","\n","Epoch 15: LearningRateScheduler setting learning rate to 0.0005488474.\n","Epoch 15/20\n","469/469 [==============================] - 49s 105ms/step - loss: 0.0687 - accuracy: 0.9790 - val_loss: 0.0593 - val_accuracy: 0.9818 - lr: 5.4885e-04\n","\n","Epoch 16: LearningRateScheduler setting learning rate to 0.0005185825.\n","Epoch 16/20\n","469/469 [==============================] - 47s 101ms/step - loss: 0.0653 - accuracy: 0.9792 - val_loss: 0.0598 - val_accuracy: 0.9816 - lr: 5.1858e-04\n","\n","Epoch 17: LearningRateScheduler setting learning rate to 0.000491481.\n","Epoch 17/20\n","469/469 [==============================] - 47s 101ms/step - loss: 0.0657 - accuracy: 0.9797 - val_loss: 0.0514 - val_accuracy: 0.9837 - lr: 4.9148e-04\n","\n","Epoch 18: LearningRateScheduler setting learning rate to 0.0004670715.\n","Epoch 18/20\n","469/469 [==============================] - 49s 104ms/step - loss: 0.0647 - accuracy: 0.9802 - val_loss: 0.0549 - val_accuracy: 0.9830 - lr: 4.6707e-04\n","\n","Epoch 19: LearningRateScheduler setting learning rate to 0.0004449718.\n","Epoch 19/20\n","469/469 [==============================] - 48s 102ms/step - loss: 0.0644 - accuracy: 0.9800 - val_loss: 0.0584 - val_accuracy: 0.9821 - lr: 4.4497e-04\n","\n","Epoch 20: LearningRateScheduler setting learning rate to 0.000424869.\n","Epoch 20/20\n","469/469 [==============================] - 49s 104ms/step - loss: 0.0633 - accuracy: 0.9802 - val_loss: 0.0602 - val_accuracy: 0.9820 - lr: 4.2487e-04\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7947cf0071f0>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["score = model_opt.evaluate(X_test, Y_test, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeDAtoAJdOKR","executionInfo":{"status":"ok","timestamp":1699005248168,"user_tz":-360,"elapsed":3302,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"cf2007be-87a2-4c8f-f97d-5953fc466d82"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 10ms/step - loss: 0.0579 - accuracy: 0.9824\n"]}]},{"cell_type":"code","source":["y_pred = model_opt.predict(X_test)\n","# Showing the results of predictions\n","for val in y_pred[:9]:\n","    print(np.argmax(val), end=\" \")\n","print()\n","print(y_test[:9])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbXmDWSwdOHc","executionInfo":{"status":"ok","timestamp":1698918974881,"user_tz":-360,"elapsed":5708,"user":{"displayName":"Shanjidul Islam Sadhin","userId":"13328520506245682240"}},"outputId":"da570b39-3fff-402c-dca4-45eddbf35e8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 4s 14ms/step\n","7 2 1 0 4 1 4 9 5 \n","[7 2 1 0 4 1 4 9 5]\n"]}]}]}